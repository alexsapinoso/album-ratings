---
title: "Stats 133 Final Project Code"
author: 'Alex Sapinoso, Alison Wilbur, and Sofia Villalpando'
date: "2024-03-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading the data

```{r}
# Packages
library(readr)
library(dplyr)
library(tm)
library(tidytext)
library(SnowballC)
# visualizations
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(reshape2)
# sentiments
library(syuzhet)
# model
library(caTools)
library(randomForest)
library(readxl)
# loading the data
pitchfork <- read_excel("pitchfork_reviews.xlsx", sheet = "Result 1")
dim(pitchfork)
pitchfork <- pitchfork %>% filter(score != "Not Available")
# from 25,708 observations to 25, 110 observations
dim(pitchfork)
pitchfork <- pitchfork %>% mutate_if(is.character, as.factor)
```

# Exploratory Data Analysis

```{r}
pitchfork$score <- as.numeric(as.vector(pitchfork$score))
table(pitchfork$score)
median(pitchfork$score, na.rm = TRUE)
# median = 7.3, most albums in 6-8 range
max(pitchfork$score, na.rm = TRUE)
min(pitchfork$score, na.rm = TRUE)
mean(pitchfork$score, na.rm = TRUE)
# Barplot of scores
as.data.frame(pitchfork) %>% mutate(med = median(score)) %>% 
  ggplot(aes(x = score, y = med)) + geom_histogram(stat="identity", fill = "darkolivegreen") + 
  geom_density() + ggtitle("Distribution of Score")
# table of mean median min max
tab <- matrix(c(7.080, 7.3, 10, 0), ncol=4, byrow=TRUE)
colnames(tab) <- c('Mean','Median','Minimum', 'Maximum')
rownames(tab) <- c('Score')
tab <- as.table(tab)
tab
```

# High Scoring Albums

```{r}
pitchfork$highscore <- rep(NA, nrow(pitchfork))
for (i in 1:nrow(pitchfork)){
  if (pitchfork$score[i] > 7.3){
    pitchfork$highscore[i] <- 1
  } else {
    pitchfork$highscore[i] <- 0
  }
}
table(pitchfork$highscore)
```

# Cleaning the data

```{r}
# Create text corpus
pitchfork.corp <- VCorpus(VectorSource(pitchfork$review))
pitchfork.corp <- tm_map(pitchfork.corp, PlainTextDocument)
# Preprocessing text
pitchfork.corp <- tm_map(pitchfork.corp, content_transformer(tolower)) # convert to lowercase
pitchfork.corp <- tm_map(pitchfork.corp, removePunctuation) # remove punctuation
pitchfork.corp <- tm_map(pitchfork.corp, removeWords, stopwords("english")) # remove stopwords
pitchfork.corp <- tm_map(pitchfork.corp, removeWords, c("album", "music", "songs", "song")) # remove own stopwords
pitchfork.corp <- tm_map(pitchfork.corp, stripWhitespace) # strip whitespace
pitchfork.corp <- tm_map(pitchfork.corp, stemDocument) # stemming
```

# Word Associations

```{r}
pitchfork.dtm <- DocumentTermMatrix(pitchfork.corp)
dtms <- removeSparseTerms(pitchfork.dtm, 0.90) # removing sparse terms
dim(dtms)
inspect(dtms)
# Correlation Plots
library(tm)
library(Rgraphviz)
plot(pitchfork.dtm, terms = findFreqTerms(pitchfork.dtm, lowfreq = 30000), corThreshold = 0.10)
```

# Sentiment Analysis

```{r}
nrc <- get_nrc_sentiment(as.character(pitchfork$review))
nrcplot <- sort(colSums(prop.table(nrc[, 1:10])))
barplot(nrcplot, col = brewer.pal(8, "Dark2")) # dist of sentiments
```

```{r}
# using ggplot for pie graph of negative and positive
pie.graph <- data.frame(emotion = names(sort(colSums(prop.table(nrc[, 9:10])))), proportion = colSums(prop.table(nrc[, 9:10])))
 ggplot(pie.graph, aes(x="", y=proportion, fill=emotion))+geom_bar(width = 1, stat = "identity")+coord_polar("y", start=0)+scale_fill_brewer(palette="Greens")+theme_minimal()
 # using ggplot for pie graph of distribution of nrc sentiments
pie.graph <- data.frame(emotion = names(sort(colSums(prop.table(nrc[, 2:10])))), proportion = colSums(prop.table(nrc[, 2:10])))
 ggplot(pie.graph, aes(x="", y=proportion, fill=emotion))+geom_bar(width = 1, stat = "identity")+coord_polar("y", start=0)+scale_fill_brewer(palette="Greens")+theme_minimal()
```

```{r}
# Creating df for sentiment analysis
review <- pitchfork$review
length(review)
pitchfork.df <- tibble(line = 1:25110, text = review)
dim(pitchfork.df)
# Tokenizing
pitchfork.df <- mutate(pitchfork.df, text = as.character(pitchfork$review))
bing <- get_sentiments("bing")
pitchfork.df %>% unnest_tokens(word, text) %>% inner_join(bing)
# Positive Negative Together
nrc_positive <- get_sentiments("nrc") %>% filter(sentiment == "positive")
nrc_negative <- get_sentiments("nrc") %>% filter(sentiment == "negative")
pos_neg <- rbind(pitchfork.df %>% unnest_tokens(word, text) %>% inner_join(nrc_negative), pitchfork.df %>% unnest_tokens(word, text) %>% inner_join(nrc_positive))
dd <- data.frame(pos_neg[,2:3])
pos_neg %>% ggplot(aes(sentiment, "")) + geom_col() + xlab(NULL) + ylab("Proportion")
# Too many words to plot, use filter(n > k)
pos_neg_Freq <- rbind(pitchfork.df %>% unnest_tokens(word, text) %>% inner_join(nrc_negative), pitchfork.df %>% unnest_tokens(word, text) %>% inner_join(nrc_positive)) %>% count(word, sort = TRUE) %>% filter(n > 10000)
pos_neg_Freq
pos_neg_Freq %>% ggplot(aes(word, n)) + geom_col() + xlab(NULL) +ylab("Count")
```

# N-grams

```{r}
# Bigrams
pitch.bigrams <- pitchfork.df %>% unnest_tokens(bigram, text, token = "ngrams", n = 2)
pitch.bigrams
# Counting and Filtering
pitch.bigrams %>% count(bigram, sort = TRUE) %>% filter(n > 10000) %>% ggplot(aes(bigram, n)) + geom_col() + xlab(NULL) + ylab("Count") + coord_flip()
# Avoiding stop words
library(tidyr)
bigrams_separated <- pitch.bigrams %>% separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>% filter(!word1 %in% stop_words$word) %>% filter(!word2 %in% stop_words$word)
# new bigram counts:
bigram_counts <- bigrams_filtered %>% count(word1, word2, sort = TRUE) 
bigram_counts
bigrams_united <- bigrams_filtered %>% unite(bigram, word1, word2, sep = " ") 
bigrams_united %>% count(bigram, sort = TRUE)
# tf-idf
bigram_tf_idf <- bigrams_united %>% count(line, bigram) %>% bind_tf_idf(bigram, line, n) %>% arrange(desc(tf_idf))
bigram_tf_idf
# not words
bigrams_separated %>% filter(word1 == "not") %>% count(word1, word2, sort = TRUE)
AFINN <- get_sentiments("afinn")
not_words <- bigrams_separated %>% filter(word1 == "not") %>% inner_join(AFINN, by = c(word2 = "word")) %>% count(word2, value, sort = TRUE)
not_words %>% mutate(contribution = n * value) %>% arrange(desc(abs(contribution))) %>% head(20) %>% mutate(word2 = reorder(word2, contribution)) %>% ggplot(aes(word2, n * value, fill = n * value > 0)) + geom_col(show.legend = FALSE) + xlab("Words preceded by \"not\"") + ylab("Sentiment value * number of occurrences") + coord_flip()
# visualizing bigrams network
library(igraph)
bigram_graph <- bigram_counts %>% filter(n > 300) %>%graph_from_data_frame() 
bigram_graph
library(ggraph)
set.seed(12345)
ggraph(bigram_graph, layout = "fr") + geom_edge_link() +geom_node_point() +geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```

# Predictive Model

```{r}
# Word Frequencies
frequencies <- DocumentTermMatrix(pitchfork.corp) # create dtm
sparse <- removeSparseTerms(frequencies, 0.995) # remove sparse terms
pitchfork.sparse <- as.data.frame(as.matrix(sparse)) # convert format
colnames(pitchfork.sparse) <- make.names(colnames(pitchfork.sparse)) # change variable names
pitchfork.sparse$highscore <- pitchfork$highscore

# Baseline accuracy
prop.table(table(pitchfork$highscore))
# about 47.6% of the albums have high scores

# Split data into Training and Testing 
set.seed(12345)
split <- sample.split(pitchfork.sparse$highscore, SplitRatio = 0.7)
trainSparse <- subset(pitchfork.sparse, split == FALSE)
testSparse <- subset(pitchfork.sparse, split == TRUE)
dim(trainSparse)
dim(testSparse)
prop.table(table(trainSparse$highscore))
prop.table(table(testSparse$highscore))
# the random forest model did not run after a day of running the code; unsuccessful on this end
```

# Word Clouds

```{r}
library(wordcloud)
set.seed(12345)
tidy.pitchfork <- pitchfork.df %>% unnest_tokens(word, text) %>% anti_join(stop_words)
tidy.pitchfork %>% count(word) %>% with(wordcloud(word, n, color= "darkolivegreen", random.color = F, min.words = 10, max.words = 100))
```

```{r}
library(wordcloud2)
set.seed(12345)
t.pf <- data.frame(tidy.pitchfork %>% count(word))
wordcloud2(t.pf, minSize = 20)
```

# Top Frequent Words

```{r}
tidy.pitchfork %>% count(word, sort = TRUE) %>% filter(n > 10000) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip()
```

# LDA

```{r}
library(topicmodels)
# Removing Zero-Entries
zero.entries <- which(apply(pitchfork.dtm[, 1], 1, sum) == 0)
pitchfork.lda <- LDA(pitchfork.dtm[-zero.entries, ], k = 5, control = list(seed = 12345))
pitchfork.lda
# Isolate topics
pitchfork.topics <- tidy(pitchfork.lda, matrix = "beta")
pitchfork.topics
# Finding the Top Ten Terms
pitchfork.top.terms <- pitchfork.topics %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>% arrange(topic, -beta)
# Plot the Top Terms for each Topic
pitchfork.top.terms %>% mutate(term = reorder_within(term, beta, topic)) %>% ggplot(aes(term, beta, fill = factor(topic))) + geom_col(show.legend = FALSE) + facet_wrap(~topic, scales = "free") + coord_flip() + scale_x_reordered()
```

# Term Association

```{r}
pitchfork.tdm <- TermDocumentMatrix(pitchfork.corp)
pitchfork.tdm
pitchfork.dtm
```

